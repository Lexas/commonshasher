First attempt at making a distributed script for hashing image collections.
It only 'works' with wikicommons dumps at the moment.

# Installation

Ubuntu package dependencies:

    python3 rabbitmq

pip package dependencies (recommended to install in a virtualenv):

    celery requests sqlalchemy lxml

To configure, copy config.py to config_local.py and change the values.

To run, seed the database first by running load_commons.py
with a file containing a dump of articles:

    python3 load_commons.py -i commonswiki-20140823-pages-articles.xml.bz2

To start the hasher, run:

    celery -A hasher worker

Queue a number of works, e.g. 1000:

    python3 enqueue.py 1000
